{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49222072-530f-4953-a405-154f61b058a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716021f2-4589-4acd-b9f0-e8e9bf81ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "# 提供一种方式取获取数据及其lable\n",
    "# 如何获取一个数据集\n",
    "# 告诉我们有多少数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df8e65-5dc0-4408-b8f2-2b4bef34afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "# 为后面网络提供不同的数据形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbcf2ed1-b078-4565-b75a-e4144d25ebef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset in module torch.utils.data.dataset:\n",
      "\n",
      "class Dataset(typing.Generic)\n",
      " |  An abstract class representing a :class:`Dataset`.\n",
      " |\n",
      " |  All datasets that represent a map from keys to data samples should subclass\n",
      " |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      " |  data sample for a given key. Subclasses could also optionally overwrite\n",
      " |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      " |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      " |  of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
      " |  optionally implement :meth:`__getitems__`, for speedup batched samples\n",
      " |  loading. This method accepts list of indices of samples of batch and returns\n",
      " |  list of samples.\n",
      " |\n",
      " |  .. note::\n",
      " |    :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
      " |    sampler that yields integral indices.  To make it work with a map-style\n",
      " |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __add__(self, other: 'Dataset[_T_co]') -> 'ConcatDataset[_T_co]'\n",
      " |\n",
      " |  __getitem__(self, index) -> +_T_co\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {}\n",
      " |\n",
      " |  __orig_bases__ = (typing.Generic[+_T_co],)\n",
      " |\n",
      " |  __parameters__ = (+_T_co,)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |\n",
      " |  __class_getitem__(...)\n",
      " |      Parameterizes a generic class.\n",
      " |\n",
      " |      At least, parameterizing a generic class is the *main* thing this\n",
      " |      method does. For example, for some generic class `Foo`, this is called\n",
      " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |\n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo[T]: ...`.\n",
      " |\n",
      " |  __init_subclass__(...)\n",
      " |      Function to initialize subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cca3797c-2cea-4c47-a7bd-ad5c49b9bd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m        \n",
       "\u001b[1;32mclass\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGeneric\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_T_co\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34mr\"\"\"An abstract class representing a :class:`Dataset`.\n",
       "\n",
       "    All datasets that represent a map from keys to data samples should subclass\n",
       "    it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
       "    data sample for a given key. Subclasses could also optionally overwrite\n",
       "    :meth:`__len__`, which is expected to return the size of the dataset by many\n",
       "    :class:`~torch.utils.data.Sampler` implementations and the default options\n",
       "    of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
       "    optionally implement :meth:`__getitems__`, for speedup batched samples\n",
       "    loading. This method accepts list of indices of samples of batch and returns\n",
       "    list of samples.\n",
       "\n",
       "    .. note::\n",
       "      :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
       "      sampler that yields integral indices.  To make it work with a map-style\n",
       "      dataset with non-integral indices/keys, a custom sampler must be provided.\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_T_co\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Subclasses of Dataset should implement __getitem__.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# def __getitems__(self, indices: List) -> List[_T_co]:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# Not implemented to prevent false-positives in fetcher check in\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Dataset[_T_co]\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"ConcatDataset[_T_co]\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mConcatDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# No `def __len__(self)` default?\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# in pytorch/torch/utils/data/sampler.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m           g:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     IterableDataset, TensorDataset, StackDataset, ConcatDataset, Subset, MapDataPipe"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edc2356-1d6b-441a-bf95-5ae8c66ea5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5430c4d8-34e3-48cf-a551-22765e79cb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e559e-1f2f-4783-8118-912065148d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
